#!/usr/bin/env python3
"""
–£–º–Ω–∞—è –¥–µduplication —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
–í—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à—É—é –∫–æ–ø–∏—é –∏–∑ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –¥—É–±–ª–µ–π
"""

import json
import os
import hashlib
from pathlib import Path
from PIL import Image
from collections import defaultdict
from datetime import datetime

PHOTO_DIRS = [
    Path(r"C:\Google_foto\EXPORT_TO_DROPBOX"),
    Path(r"C:\Google_foto\EXPORT_TO_DROPBOX1"),
    Path(r"C:\Users\alimg\Dropbox\Archiwum 3.0\00_INBOX\_PHOTO_DEDUP"),
]

METADATA_CACHE = Path(r"C:\Users\alimg\Dropbox\Archiwum 3.0\99_SYSTEM\PHOTO_METADATA_CACHE.json")
OUTPUT_REPORT = Path(r"C:\Users\alimg\Dropbox\Archiwum 3.0\00_INBOX\DEDUP_CANDIDATES.csv")

def get_image_quality(filepath):
    """–í–µ—Ä–Ω—É—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ: (—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ, —Ä–∞–∑–º–µ—Ä, —Ñ–æ—Ä–º–∞—Ç)"""
    try:
        img = Image.open(filepath)
        width, height = img.size
        filesize = filepath.stat().st_size
        fmt = img.format
        return (width * height, filesize, fmt)  # (–º–µ–≥–∞–ø–∏–∫—Å–µ–ª–∏, —Ä–∞–∑–º–µ—Ä_–±–∞–π—Ç—ã, —Ñ–æ—Ä–º–∞—Ç)
    except Exception:
        return (0, 0, "UNKNOWN")

def calculate_sha256(filepath):
    """–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å SHA256"""
    sha = hashlib.sha256()
    try:
        with open(filepath, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                sha.update(chunk)
        return sha.hexdigest()
    except Exception:
        return None

def build_duplicate_groups():
    """–ù–∞–π—Ç–∏ –≥—Ä—É–ø–ø—ã –¥—É–±–ª–µ–π –ø–æ SHA256"""
    print("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ...")
    
    hash_map = defaultdict(list)
    total_files = 0
    
    for photo_dir in PHOTO_DIRS:
        if not photo_dir.exists():
            continue
        
        for photo_file in photo_dir.rglob('*'):
            if not photo_file.is_file():
                continue
            
            if photo_file.suffix.lower() not in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.mp4', '.mov']:
                continue
            
            total_files += 1
            sha = calculate_sha256(photo_file)
            if sha:
                hash_map[sha].append(str(photo_file))
            
            if total_files % 100 == 0:
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_files} —Ñ–∞–π–ª–æ–≤...")
    
    # –û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –¥—É–±–ª–∏ (–≥—Ä—É–ø–ø—ã > 1)
    duplicates = {sha: files for sha, files in hash_map.items() if len(files) > 1}
    
    print(f"‚úì –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_files}")
    print(f"‚úì –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(hash_map)}")
    print(f"‚úì –ì—Ä—É–ø–ø –¥—É–±–ª–µ–π: {len(duplicates)}")
    
    return duplicates

def choose_best_file(group):
    """–í—ã–±—Ä–∞—Ç—å –ª—É—á—à—É—é –∫–æ–ø–∏—é –∏–∑ –≥—Ä—É–ø–ø—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É/—Ä–∞–∑–º–µ—Ä—É"""
    
    # –û—Ü–µ–Ω–∏—Ç—å –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    scored = []
    for filepath in group:
        path_obj = Path(filepath)
        resolution, filesize, fmt = get_image_quality(filepath)
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: 1) —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ 2) —Ä–∞–∑–º–µ—Ä 3) –Ω–æ–≤–∏–∑–Ω–∞
        mtime = path_obj.stat().st_mtime
        score = (resolution, filesize, mtime)  # –ö–æ—Ä—Ç–µ–∂ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        
        scored.append((filepath, score, resolution, filesize, fmt))
    
    # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –æ—Ü–µ–Ω–∫–µ (–ª—É—á—à–∏–π = –ø–æ—Å–ª–µ–¥–Ω–∏–π)
    scored.sort(key=lambda x: x[1])
    best = scored[-1]
    
    return best[0], scored

def generate_dedup_report(duplicates):
    """–°–æ–∑–¥–∞—Ç—å –æ—Ç—á–µ—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏"""
    
    print("\nüìù –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç—á–µ—Ç...n")
    
    lines = [
        "SHA256,–õ—É—á—à–∞—è_–∫–æ–ø–∏—è,–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ_px,–†–∞–∑–º–µ—Ä_MB,–§–æ—Ä–º–∞—Ç,–î—É–±–ª–∏_–≤_–≥—Ä—É–ø–ø–µ,–≠–∫–æ–Ω–æ–º–∏—è_MB",
    ]
    
    total_savings = 0
    total_groups = len(duplicates)
    
    for idx, (sha, group) in enumerate(duplicates.items(), 1):
        best_file, scored = choose_best_file(group)
        best_res, best_size, best_fmt = None, None, None
        
        for filepath, score, res, size, fmt in scored:
            if filepath == best_file:
                best_res, best_size, best_fmt = res, size, fmt
                break
        
        # –°—á–∏—Ç–∞—Ç—å —ç–∫–æ–Ω–æ–º–∏—é
        other_files = [f for f in group if f != best_file]
        savings = sum(Path(f).stat().st_size for f in other_files) / (1024 * 1024)
        total_savings += savings
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É
        line = f"{sha[:8]},{Path(best_file).name},{best_res},{best_size/1024/1024:.1f},{best_fmt},{len(group)},{savings:.1f}"
        lines.append(line)
        
        if (idx % 50) == 0:
            print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx}/{total_groups}")
    
    # –ó–∞–ø–∏—Å–∞—Ç—å –æ—Ç—á–µ—Ç
    with open(OUTPUT_REPORT, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))
    
    print(f"\n‚úì –û—Ç—á–µ—Ç: {OUTPUT_REPORT}")
    print(f"‚úì –í–æ–∑–º–æ–∂–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏—è: {total_savings:.1f} MB ({total_savings/1024:.2f} GB)")
    print(f"‚úì –ì—Ä—É–ø–ø –¥—É–±–ª–µ–π: {total_groups}")
    
    return OUTPUT_REPORT, total_savings

def main():
    print("=" * 60)
    print("  –£–ú–ù–ê–Ø DEDUPLICATION –° –§–ò–õ–¨–¢–†–ê–ú–ò")
    print("=" * 60)
    
    duplicates = build_duplicate_groups()
    
    if not duplicates:
        print("‚úì –î—É–±–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
        return
    
    report_path, savings = generate_dedup_report(duplicates)
    
    print("\n" + "=" * 60)
    print(f"–§–ò–õ–¨–¢–†–´ –í–´–ë–û–†–ê –õ–£–ß–®–ï–ô –ö–û–ü–ò–ò:")
    print("  1Ô∏è‚É£  –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ (–≤—ã—à–µ = –ª—É—á—à–µ)")
    print("  2Ô∏è‚É£  –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–±–æ–ª—å—à–µ = –ª—É—á—à–µ)")
    print("  3Ô∏è‚É£  –î–∞—Ç–∞ (–Ω–æ–≤–µ–µ = –ª—É—á—à–µ)")
    print("\n–û—Ç—á–µ—Ç –≥–æ—Ç–æ–≤! –°–º–æ—Ç—Ä–∏:", report_path)
    print("=" * 60)

if __name__ == "__main__":
    main()
